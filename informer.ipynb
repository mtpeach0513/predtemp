{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'flood_data/train/*.csv'\n",
    "VALID_PATH = 'flood_data/valid/*.csv'\n",
    "#TEST_PATH = 'flood_data/test/*.csv'\n",
    "PASS = 'data/masterFileForLean_2017_2019.csv'\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "\n",
    "def load_csv(filepath):\n",
    "    files = glob.glob(filepath)\n",
    "    lis = []\n",
    "    for filename in files:\n",
    "        parser = lambda date: pd.to_datetime(date, format='%Y%m%d%H')\n",
    "        df = pd.read_csv(filename, index_col=0, parse_dates=True, date_parser=parser,\n",
    "                    usecols=[\n",
    "                        0, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
    "                        14, 15, 16, 17, 18, 20, 21, 22, 23, 24,\n",
    "                        26, 27, 28, 29, 30, 32, 33, 34, 35, 36,\n",
    "                        38, 39, 40, 41, 42, 44, 45, 46, 47, 48,\n",
    "                        50, 51, 52, 53, 54, 56, 57, 58, 59, 60,\n",
    "                        62, 63, 64, 65, 66, 68, 69, 70, 71, 72,\n",
    "                        106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
    "                        116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
    "                        126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
    "                        136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "                        146, 147, 148, 149, 150, 186\n",
    "                    ])\n",
    "        lis.append(df)\n",
    "        df = pd.concat(lis, axis=0)\n",
    "        df.index.name = 'date'\n",
    "    return df\n",
    "\n",
    "data = load_csv(PASS)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rcParams['figure.figsize'] = 30,30\n",
    "data.hist(bins=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_hist.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv('data/2020.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.root_path = 'data/' # root path of data file\n",
    "args.data_path = 'dataset.csv' # data file\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'A_temp' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = 'checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 12 #96 # input sequence length of Informer encoder\n",
    "args.label_len = 6 #48 # start token length of Informer decoder\n",
    "args.pred_len = 3 #24 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 7 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'relu' #'gelu' # activation\n",
    "args.padding == 0\n",
    "args.distil = False #True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "\n",
    "args.batch_size = 16 #32 \n",
    "args.learning_rate = 0.01 #0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 6\n",
    "args.patience = 10\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'custom':{'data':'dataset.csv', 'T':'A_temp', 'M':[105,105,105], 'S':[1,1,1], 'MS':[105,105,1]}\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting = 'informer_custom_ftMS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_exp_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp(args)\n",
    "#exp.predict(setting, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the detailed code of function predict\n",
    "\n",
    "def predict(exp, setting, load=False):\n",
    "    pred_data, pred_loader = exp._get_data(flag='pred')\n",
    "        \n",
    "    if load:\n",
    "        path = os.path.join(exp.args.checkpoints, setting)\n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        exp.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    exp.model.eval()\n",
    "        \n",
    "    preds = []\n",
    "        \n",
    "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:,-exp.args.pred_len:,:]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "        # encoder - decoder\n",
    "        if exp.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if exp.args.output_attention:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if exp.args.output_attention:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        f_dim = -1 if exp.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-exp.args.pred_len:,f_dim:].to(exp.device)\n",
    "        \n",
    "        pred = outputs.detach().cpu().numpy()#.squeeze()\n",
    "        \n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    \n",
    "    # result save\n",
    "    folder_path = './results/' + setting +'/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    np.save(folder_path+'real_prediction.npy', preds)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use this prediction function to get result\n",
    "prediction = predict(exp, setting, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prediction[0,:,-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import Dataset_Pred\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Dataset_Pred\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'pred'; shuffle_flag = False; drop_last = False; batch_size = 1\n",
    "\n",
    "freq = args.detail_freq\n",
    "\n",
    "data_set = Data(\n",
    "    root_path=args.root_path,\n",
    "    data_path=args.data_path,\n",
    "    flag=flag,\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    target=args.target,\n",
    "    timeenc=timeenc,\n",
    "    freq=freq\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_set), len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 視覚化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "preds = np.load('./results/'+setting+'/pred.npy')\n",
    "trues = np.load('./results/'+setting+'/true.npy')\n",
    "reals = np.load('./results/'+setting+'/real_prediction.npy')\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "preds.shape, trues.shape, reals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "new_pred = scaler.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_pred[:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PASS = 'result_img/' + setting\n",
    "os.makedirs(SAVE_PASS, exist_ok=True)\n",
    "filename = os.path.join(SAVE_PASS, setting+'.png')\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw OT prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[:,:,-1], label='GroundTruth')\n",
    "plt.plot(preds[:,:,-1], label='Prediction')\n",
    "plt.legend()\n",
    "plt.savefig(filename, dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A_temp'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A_temp'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
